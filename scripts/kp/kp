#!/usr/bin/env python
#
# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES.
# All rights reserved. SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

import argparse
import os
import re
import subprocess
import time
from io import BytesIO
from urllib.request import urlopen

import pandas as pd
import plotly.graph_objects as go
import plotly.io as pio
from PIL import Image
from plotly.colors import qualitative
from tqdm import tqdm

IMGS = ["torch", "tf", "parrot", "cupy", "jax", "matx", "thrust", "cuda", "arrayfire"]

def remove_matching_angle_brackets(text, brackets):
    result = []
    stack = []
    for char in text:
        if char == brackets[0]:
            stack.append(len(result))
        elif char == brackets[1] and stack:
            start_idx = stack.pop()
            result = result[:start_idx]
        else:
            result.append(char)
    return "".join(result)


def after(s: str, t: str) -> str:
    return s[s.index(t) + len(t) :]


def before(s: str, t: str) -> str:
    return s[: s.index(t)]


def preprocess_kernel_name(name):
    backup = name
    name = remove_matching_angle_brackets(name, "<>")
    name = remove_matching_angle_brackets(name, "()")
    name = re.sub(r"void ", "", name)
    if "::" in name:
        name = "::".join(x for x in name.split("::") if not any(c.isdigit() for c in x))
        name = re.sub(r"::::", "::", name)
    if "kernel_agent" in name:
        inner = preprocess_kernel_name(after(backup, "<"))
        name = name.split("::")[-1]
        return f"{name}<{before(inner, ",")}>"
    return name.strip()


def load_kernel_data(file_path):
    try:
        data = pd.read_csv(file_path)
        data["Name"] = data["Name"].apply(preprocess_kernel_name)
        return data[["Name", "Total Time (ns)", "Instances"]]
    except Exception as e:
        print(f"Error reading {file_path}: {e}")
        return None


def rotate(lst, n):
    return lst[n:] + lst[:n]


def create_stacked_bar_chart(data_frames, labels, chart_name, export_html):
    sorted_data = sorted(
        zip(data_frames, labels),
        key=lambda pair: (
            pair[0]["Total Time (ns)"].sum() // (100 if "matx" in pair[1] else 1)
            if pair[0] is not None
            else 0
        ),
        reverse=True,
    )
    data_frames, labels = zip(*sorted_data)

    # Generate full version
    fig_full = _create_figure(
        data_frames,
        labels,
        chart_name,
        hoverlabel_size=30,
        show_annotations=True,
        top_margin=100,
    )

    if export_html:
        # Export full version
        pio.write_html(fig_full, file=f"{chart_name}_full.html", auto_open=False)

        # Generate and export mini version
        fig_mini = _create_figure(
            data_frames,
            labels,
            chart_name,
            hoverlabel_size=12,
            show_annotations=False,
            top_margin=75,
        )
        pio.write_html(fig_mini, file=f"{chart_name}_mini.html", auto_open=False)

    fig_full.show()


def _create_figure(
    data_frames, labels, chart_name, hoverlabel_size, show_annotations, top_margin
):
    """Helper function to create a figure with specific styling parameters."""
    fig = go.Figure()
    totals = []
    instance_counts = []
    color_palette = rotate(qualitative.Plotly, 7)
    n = len(qualitative.Plotly)

    for df, label in zip(data_frames, labels):
        if df is not None:
            div_factor = 100 if "matx" in label else 1
            totals.append(df["Total Time (ns)"].sum() // div_factor)
            instance_counts.append(df["Instances"].sum() // div_factor)
            for i, row in df.iterrows():
                fig.add_trace(
                    go.Bar(
                        name=row["Name"],
                        x=[label],
                        y=[row["Total Time (ns)"] / div_factor],
                        hoverinfo="text",
                        hoverlabel=dict(font_size=hoverlabel_size),
                        text=(
                            f"{row['Name']} "
                            f"({row['Total Time (ns)']} ns | {row['Instances']})"
                        ),
                        marker_color=color_palette[i % n],
                    )
                )

    max_total = max(totals)

    if show_annotations:
        for i, (total, count) in enumerate(zip(totals, instance_counts)):
            fig.add_annotation(
                x=labels[i],
                y=total,
                text=f"Total: {total:,} Kernels: {count}",
                showarrow=True,
                ax=0,
                ay=-40,
                font=dict(size=12, color="black"),
                align="center",
                bgcolor="rgba(255, 255, 255, 0.8)",
                borderpad=5,
                bordercolor="black",
                borderwidth=2,
            )

    # Add logo images
    for i, (total, count) in enumerate(zip(totals, instance_counts)):
        for name in IMGS:
            if name in labels[i]:
                # Add cache-busting parameter to force fresh image download
                cache_buster = int(time.time())
                image_url = f"https://raw.githubusercontent.com/codereport/parrot-cpp-extra/main/profiling/assets/{name}.png?cb={cache_buster}"
                try:
                    with urlopen(image_url) as response:
                        image_data = response.read()
                    img = Image.open(BytesIO(image_data))
                    fig.add_layout_image(
                        dict(
                            source=img,
                            xref="x",
                            yref="paper",
                            x=labels[i],
                            y=(
                                (total / max_total) + 0.075
                                if total < max_total * 0.75
                                else 0.025
                            ),
                            sizex=0.5,
                            sizey=0.5,
                            xanchor="center",
                            yanchor="bottom",
                        )
                    )
                except Exception as e:
                    print(f"Warning: Could not load image for {name}: {e}")
                break

    # Set smaller margins for mini version
    margin_settings = (
        dict(t=top_margin, l=60, r=40, b=60)
        if not show_annotations
        else dict(t=top_margin)
    )

    fig.update_layout(
        barmode="stack",
        title=f"CUDA Kernel Profiling ({chart_name})",
        yaxis_title="Total Time (ns)",
        hovermode="x",
        showlegend=False,
        bargap=0.2,
        margin=margin_settings,
    )

    return fig


def run_nsys(file_path, output_dir, verbose):
    base_name = os.path.splitext(os.path.basename(file_path))[0]
    output_name = os.path.join(output_dir, base_name)
    file_path = os.path.abspath(file_path)
    command = [
        "nsys",
        "profile",
        "--trace=cuda",
        "-o",
        output_name,
    ]
    if file_path.endswith(".py"):
        command += ["python"]
    command += [file_path]
    try:
        if verbose:
            subprocess.run(command, check=True)
        else:
            subprocess.run(command, capture_output=True, text=True)
    except subprocess.CalledProcessError as e:
        print(f"Error running nsys on {file_path}: {e}")
    return output_name + ".nsys-rep", output_name + ".sqlite"


def generate_csv(nsys_rep, base_name, verbose):
    command = [
        "nsys",
        "stats",
        "--force-overwrite",
        "true",
        "--report",
        "cuda_gpu_kern_sum",
        "--report",
        "cuda_api_sum",
        "--format",
        "csv,csv",
        "--output",
        base_name + "," + base_name,
        nsys_rep,
    ]
    try:
        if verbose:
            subprocess.run(command, check=True)
        else:
            subprocess.run(command, capture_output=True, text=True)
    except subprocess.CalledProcessError as e:
        print(f"Error generating CSV files from {nsys_rep}: {e}")


def clean_up(files):
    for file in files:
        if os.path.exists(file):
            os.remove(file)


def run_profiler(args):
    subdir_path = os.path.join(os.getcwd(), args.subdir)
    files = [
        f for f in os.listdir(subdir_path) if f.endswith(".py") or f.endswith("_cu")
    ]

    if args.filter:
        files = [f for f in files if args.filter in f]

    output_dir = os.path.join(subdir_path, "nsys_results")
    os.makedirs(output_dir, exist_ok=True)

    for file in tqdm(files, desc="Profiling files"):
        file_path = os.path.join(subdir_path, file)
        if args.verbose:
            print(f"âœ… Processing {file}...")
        nsys_rep, sqlite_file = run_nsys(file_path, output_dir, args.verbose)
        base_name = os.path.splitext(nsys_rep)[0]
        generate_csv(nsys_rep, base_name, args.verbose)
        clean_up([nsys_rep, sqlite_file])


def run_plotter(args):
    results_dir = os.path.join(args.subdir, "nsys_results")
    data_frames = []
    labels = []
    if not os.path.isdir(results_dir):
        print(f"Directory {results_dir} does not exist or is invalid.")
        return

    for file_name in os.listdir(results_dir):
        if file_name.endswith("_cuda_gpu_kern_sum.csv"):
            file_path = os.path.join(results_dir, file_name)
            df = load_kernel_data(file_path)
            if df is not None:
                data_frames.append(df)
                labels.append(file_name.replace("_cuda_gpu_kern_sum.csv", ""))

    if data_frames:
        create_stacked_bar_chart(data_frames, labels, args.subdir, args.export_html)
    else:
        print("No valid CSV files found in the directory.")


def main():
    parser = argparse.ArgumentParser(
        description="Run nsys profiling and generate plots."
    )
    parser.add_argument(
        "subdir",
        help="name of the subdirectory containing python files (e.g. sf2, mgc).",
    )
    parser.add_argument(
        "-p",
        "--plot-only",
        action="store_true",
        help="skip profiling and only generate plots",
    )
    parser.add_argument(
        "-v",
        "--verbose",
        action="store_true",
        help="enable verbose output during profiling",
    )
    parser.add_argument(
        "-f",
        "--filter",
        help="only profile Python files containing this string",
    )
    parser.add_argument(
        "-e", "--export-html", help="export plot as HTML file", action="store_true"
    )

    args = parser.parse_args()

    if not args.plot_only:
        run_profiler(args)

    run_plotter(args)


if __name__ == "__main__":
    main()
